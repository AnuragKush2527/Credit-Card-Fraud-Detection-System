# Credit Card Fraud Detection System

# ğŸ“Œ Project Overview

This project aims to detect fraudulent credit card transactions using machine learning. We use the Credit Card Fraud Detection dataset from Kaggle, which contains anonymized transaction details and labels indicating fraud or legitimate transactions. A Logistic Regression model is trained to classify transactions as fraudulent or legitimate.

# ğŸ“Š Dataset

The dataset used in this project is publicly available on Kaggle:ğŸ”—https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

**Dataset Description**

The dataset contains 284,807 transactions.

It includes 30 features, with the Class column indicating fraud (1) or legitimate (0).

Features are numerical, transformed using PCA (Principal Component Analysis).

**How to Download the Dataset**

Visit the dataset link.

Click Download and extract the creditcard.csv file.

Place creditcard.csv in the project directory.

If using Google Colab, download the dataset with:

!kaggle datasets download -d mlg-ulb/creditcardfraud
!unzip creditcardfraud.zip

# ğŸ› ï¸ Installation & Setup

**Step 1: Clone the Repository**

git clone https://github.com/anuragkush2527/credit-card-fraud-detection.git
cd credit-card-fraud-detection

**Step 2: Install Dependencies**

Ensure you have Python installed, then install dependencies using:

pip install -r requirements.txt

**Step 3: Run the Jupyter Notebook**

Launch Jupyter Notebook and open fraud_detection.ipynb:

jupyter notebook

# ğŸ“Œ Project Workflow

Load dataset (creditcard.csv)

Data Exploration & Preprocessing

Check for missing values

Analyze fraud vs. non-fraud transaction distribution

Perform feature scaling using StandardScaler

Data Balancing

The dataset is highly imbalanced (fraud cases are rare)

Use undersampling to create a balanced dataset

Model Training

Train Logistic Regression on balanced data

Split dataset into training & testing sets

Scale features using StandardScaler

Model Evaluation

Compute accuracy on training & test sets

# ğŸ” Results

Accuracy on Training Data: 95.42%

Accuracy on Test Data: 91.87%
